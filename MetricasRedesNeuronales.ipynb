{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de uso de biblioteca uk-nilm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Celda Colab\n",
    "Si se corre en Colab tendra que montar su google drive y seleccionar en ***PATH_DRIVE*** el directorio en el que esta clonado su repositorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DRIVE =  '/content/drive/My Drive/base_de_datos_nilm'\n",
    "import os\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    print(\"Estoy corriendo en Colab\")\n",
    "    %tensorflow_version 2.x\n",
    "    import tensorflow as tf\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "    if device_name != '/device:GPU:0':\n",
    "        raise SystemError('No se ha activado la GPU de Colab')\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    %cd $PATH_DRIVE\n",
    "   \n",
    "else:\n",
    "   print(\"NO estoy corriendo en Colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importo librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import uk\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargo parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECTRODOMESTICO = 'kettle' #Electrodomestico para el que se entrenara la red\n",
    "TIPO_RED = 'rectangulos' #Tipo de red a utilizar\n",
    "RUTA_DE_DATOS_X_Y = 'vectores' #Carpeta en la cual se encuentran guardados los vectores X e Y\n",
    "RUTA_DATOS_ENTRENAMIENTO = 'pesos' #Carpeta en la que se guardaran los datos generados en el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargo datos\n",
    "Los datos pueden ser generados mediante el notebook \"Procesamiento de datos\" o bajarlos desde: https://iie.fing.edu.uy/~cmarino/NILM/vectores.zip\n",
    "\n",
    "Nota: no se garantiza que los datos anteriores se encuentren accesibles en un futuro cercano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = uk.cargar_X_y('data', 'train', ruta_base = RUTA_DE_DATOS_X_Y)\n",
    "x_validacion, y_validacion = uk.cargar_X_y('data', 'validacion', ruta_base = RUTA_DE_DATOS_X_Y)\n",
    "x_test_no_visto, y_test_no_visto = uk.cargar_X_y('data', 'test_no_visto', ruta_base = RUTA_DE_DATOS_X_Y)\n",
    "x_test_visto, y_test_visto = uk.cargar_X_y('data', 'test_visto', ruta_base = RUTA_DE_DATOS_X_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train[TIPO_RED][ELECTRODOMESTICO]\n",
    "X_val = x_validacion[TIPO_RED][ELECTRODOMESTICO]\n",
    "y_train = y_train[TIPO_RED][ELECTRODOMESTICO]\n",
    "y_val = y_validacion[TIPO_RED][ELECTRODOMESTICO]\n",
    "\n",
    "X_test_no_visto = x_test_no_visto[TIPO_RED][ELECTRODOMESTICO]\n",
    "X_test_visto = x_test_visto[TIPO_RED][ELECTRODOMESTICO]\n",
    "y_test_no_visto = y_test_no_visto[TIPO_RED][ELECTRODOMESTICO]\n",
    "y_test_visto = y_test_visto[TIPO_RED][ELECTRODOMESTICO]\n",
    "\n",
    "# El expand dims es necesario para entrenar, tensorflow solicita un vector de 3 dimensiones\n",
    "X_train = np.expand_dims(\n",
    "    X_train[:, :-3], axis=2\n",
    ")\n",
    "X_val = np.expand_dims(\n",
    "    X_val[:, :-3], axis=2\n",
    ")\n",
    "\n",
    "X_test_no_visto = np.expand_dims(\n",
    "    X_test_no_visto[:, :-3], axis=2\n",
    ")\n",
    "X_test_visto = np.expand_dims(\n",
    "    X_test_visto[:, :-3], axis=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se normalizan los datos\n",
    "Para que el entrenamiento de las redes neuronales sea más efectivo es necesario normalizar los datos. <br>\n",
    "El criterio de normalización es el que aparece en la **\"Sección 3.6: Standardisation.\" del paper de Jack Kelly**.\n",
    "<br><br>\n",
    "**Entrada**: Se le resta la media a cada fila (muestra) y se divide por la media de las desviaciones estandar **de train**.<br>\n",
    "**Salida**: Se divide entre el valor máximo en potencia en train, de forma que la salida este en el rango [0,1]. Este calculo depende de que tipo de red se trate\n",
    "\n",
    "\n",
    "NOTA: Los valores utilizados para la normalización solo se calculan para entrenar salvo a la hora de restar la media. Es decir, para predecir valores se debe normalizar con la desviación estándar de train y NO de ella misma.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Normalizacion de X e y\n",
    "std_entrada = np.nanmean(np.nanstd(X_train, axis=1))\n",
    "X_train_norm = uk.utils.normalize_X(X_train, std_entrada)\n",
    "X_val_norm = uk.utils.normalize_X(X_val, std_entrada)\n",
    "\n",
    "X_test_no_visto_norm = uk.utils.normalize_X(X_test_no_visto, std_entrada)\n",
    "X_test_visto_norm = uk.utils.normalize_X(X_test_visto, std_entrada)\n",
    "\n",
    "\n",
    "if TIPO_RED=='rectangulos':\n",
    "    std_salida = np.max(y_train[:, 0]) ### Para red de rectangulos\n",
    "else:\n",
    "    std_salida = np.max(y_train) ### Para red de autoencoder\n",
    "y_train_norm = uk.utils.normalize_Y(y_train, std_salida, TIPO_RED)\n",
    "y_val_norm = uk.utils.normalize_Y(y_val, std_salida, TIPO_RED)\n",
    "\n",
    "\n",
    "y_test_no_visto_norm = uk.utils.normalize_Y(y_test_no_visto, std_salida, TIPO_RED)\n",
    "y_test_visto_norm = uk.utils.normalize_Y(y_test_visto, std_salida, TIPO_RED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se define el modelo de red neuronal utilizada\n",
    "En funcion de los parametros elegidos se carga el modelo adecuado.\n",
    "\n",
    "A continuacion se oueden observar los 2 posible modelos, el primero el de rectangulos, el segundo el de autoencoder.\n",
    "<img src=\"img/arquitecturas.jpg\"  width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[1]\n",
    "\n",
    "if TIPO_RED=='rectangulos':\n",
    "    model = uk.redes.rectangulos(input_size)\n",
    "elif TIPO_RED=='autoencoder':\n",
    "    model = uk.redes.autoencoder(input_size)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss=\"MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se cargarn los datos de entrenamiento de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "path = os.path.join(RUTA_DATOS_ENTRENAMIENTO, 'data', TIPO_RED, ELECTRODOMESTICO)\n",
    "model.load_weights(os.path.join(path, 'pesos.h5'))\n",
    "history = json.load(open(os.path.join(path, 'loss.json'), 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grafica de la loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se grafica la \"loss\". Esto es como evoluciona el error a medida que amuentan las epocas de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.title(\"Loss function through training\")\n",
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend([\"Training loss\", \"Validation loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se predicen todos los conjuntos y se compara con los valores reales\n",
    "En primera instancia se preciden todos los conjuntos y se grafican en conjunto con la serie real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    y_pred_norm = model.predict(X)\n",
    "    if TIPO_RED=='autoencoder':\n",
    "        y_pred_norm = y_pred_norm[:,:,0]\n",
    "    #Desnormalizo\n",
    "    y_pred = uk.utils.unnormalize_Y(y_pred_norm, std_salida, TIPO_RED)\n",
    "    return y_pred\n",
    "\n",
    "def plot(y_pred, X, y, cantidad=10):\n",
    "    for i in range(0,cantidad):\n",
    "        plt.figure()\n",
    "        if TIPO_RED=='autoencoder':\n",
    "            y_pred_plot = y_pred[i,:] \n",
    "            y_plot = y[i,:] \n",
    "        elif TIPO_RED=='rectangulos':\n",
    "            y_pred_plot = uk.utils.salida_rectangulos_to_serie_numpy(y_pred[i,:], size=X.shape[1])\n",
    "            y_plot = uk.utils.salida_rectangulos_to_serie_numpy(y[i,:], size=X.shape[1])\n",
    "        plt.plot(y_pred_plot, label='Predict')\n",
    "        plt.plot(X[i,:,0], label='Input')\n",
    "        plt.plot(y_plot, label='Target')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = predict(X_train_norm)\n",
    "plot(y_train_pred, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = predict(X_val_norm)\n",
    "plot(y_val_pred, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test no visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_no_visto_pred = predict(X_test_no_visto_norm)\n",
    "plot(y_test_no_visto_pred, X_test_no_visto, y_test_no_visto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_visto_pred = predict(X_test_visto_norm)\n",
    "plot(y_test_visto_pred, X_test_visto, y_test_visto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas\n",
    "Se reportan varias metricas. Todas estas se pueden ver en [Proyecto de fin de carrera (Marchsesoni-MariÃ±o-Masquil)](https://gitlab.fing.edu.uy/cmarino/base_de_datos_nilm/-/blob/master/docs/MMM20.pdf).\n",
    "\n",
    "Se dividen en 2 grupos, metricas de regresion y metricas de clasificacion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metricas de regresion\n",
    "\\begin{equation}R E I T E=\\frac{|\\hat{E}-E|}{\\max (E, \\hat{E})}\\end{equation}\n",
    "\\begin{equation}M A E=\\frac{1}{T} \\sum_{t=1}^{T}\\left|\\hat{y}_{t}-y_{t}\\right|\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metricas de clasificacion\n",
    "\\begin{equation}\\text { Recall (or True Positive Rate)} = \\frac{{TP}}{{TP}+{FN}}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\text { Precision } =\\frac{T P}{T P+F P}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\text { Accuracy }=\\frac{T P+T N}{T P+T N+F P+F N}\\end{equation}\n",
    "\n",
    "\\begin{equation}\\text { False Positive Rate }=\\frac{F P}{T N+F P}\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\\text { F1-Score }=\\frac{2 T P}{2 T P + F P + FN}\\end{equation}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Curva ROC y AUC\n",
    "Es el la grafica de Recall en funcion de False Positive Rate a medida que varia el umbral de clasificacion.\n",
    "\n",
    "La **AUC** es el area debajo de esta curva, cuanto mas cercana a 1 indica un mayor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(recalls, precisions, accuracys, fprs, f1s, threshs):\n",
    "    argmax = np.nanargmax(f1s)\n",
    "    uk.metricas.plot_roc(recalls, fprs, argmax=argmax)\n",
    "\n",
    "    reite = uk.metricas.REITE(y_train, y_train_pred, TIPO_RED)\n",
    "    mae = uk.metricas.MAE(y_train, y_train_pred, TIPO_RED)\n",
    "\n",
    "    print(f\"AUC\\t\\t\\t: {uk.metricas.auc(recalls, fprs)}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Recall\\t\\t\\t: {recalls[argmax]}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(f\"Precision\\t\\t: {precisions[argmax]}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(f\"Accuracy\\t\\t: {accuracys[argmax]}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(f\"False positive rate\\t: {fprs[argmax]}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(f\"f1-score\\t\\t: {f1s[argmax]}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(\"\\n\")\n",
    "    print(f\"REITE\\t\\t\\t: {reite}\")\n",
    "    print(\"--------------------\"*3)\n",
    "    print(f\"MAE\\t\\t\\t: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls, precisions, accuracys, fprs, f1s, threshs = uk.metricas.roc(y_train, y_train_pred, TIPO_RED)\n",
    "show_results(recalls, precisions, accuracys, fprs, f1s, threshs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls, precisions, accuracys, fprs, f1s, threshs = uk.metricas.roc(y_val, y_val_pred, TIPO_RED)\n",
    "show_results(recalls, precisions, accuracys, fprs, f1s, threshs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test no visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls, precisions, accuracys, fprs, f1s, threshs = uk.metricas.roc(y_test_no_visto, y_test_no_visto_pred, TIPO_RED)\n",
    "show_results(recalls, precisions, accuracys, fprs, f1s, threshs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Visto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recalls, precisions, accuracys, fprs, f1s, threshs = uk.metricas.roc(y_test_visto, y_test_visto_pred, TIPO_RED)\n",
    "show_results(recalls, precisions, accuracys, fprs, f1s, threshs)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,notebooks_py//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
